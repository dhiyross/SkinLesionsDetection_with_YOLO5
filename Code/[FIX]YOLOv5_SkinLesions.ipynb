{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"GrITWw57_I6P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687612758973,"user_tz":-420,"elapsed":20256,"user":{"displayName":"Rosyiidah Dhiya'Ulhaq","userId":"12255056924719099942"}},"outputId":"84b10c86-e039-42a5-b498-794c0c8c437b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#Clone Github YOLOv5"],"metadata":{"id":"YUk6fK7eWgB3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HQ0GwTx9cZz"},"outputs":[],"source":["#clone YOLOv5 and\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","%pip install -qr requirements.txt # install dependencies\n","%pip install -q roboflow\n","\n","import torch\n","import os\n","from IPython.display import Image, clear_output  # to display images\n","\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"]},{"cell_type":"code","source":["%cat /content/yolov5/models/yolov5x.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlydBgAGdUW3","outputId":"cb11d591-cfca-4775-f954-e5e938d04f23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\n","\n","# Parameters\n","nc: 80  # number of classes\n","depth_multiple: 1.33  # model depth multiple\n","width_multiple: 1.25  # layer channel multiple\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 v6.0 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 6, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 3, C3, [1024]],\n","   [-1, 1, SPPF, [1024, 5]],  # 9\n","  ]\n","\n","# YOLOv5 v6.0 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]\n"]}]},{"cell_type":"markdown","source":["#Import Dataset"],"metadata":{"id":"KoRtZWf2U8lE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0IWKNyK_h90"},"outputs":[],"source":["# set up environment\n","os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7uzklOb_jn0"},"outputs":[],"source":["#after following the link above, recieve python code with these fields filled in\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"3vYbmzP6xngL3Zufw4LR\")\n","project = rf.workspace(\"thesisyolov5-1swb8\").project(\"sl-yolov5\")\n","dataset = project.version(6).download(\"yolov5\")"]},{"cell_type":"markdown","metadata":{"id":"SBq-z4d8_2u-"},"source":["# (Opsional) Edit Model Configuration and Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4bKpOBO_8J_"},"outputs":[],"source":["# define number of classes based on YAML\n","import yaml\n","with open(dataset.location + \"/data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9I-XE14P_67a"},"outputs":[],"source":["#this is the model configuration we will use for our tutorial\n","%cat /content/yolov5/models/yolov5s.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hfsn7S0MAJ78"},"outputs":[],"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahr3wTz9AMZD"},"outputs":[],"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"]},{"cell_type":"markdown","metadata":{"id":"zxOajWVkAP0w"},"source":["# Train Custom YOLOv5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PN8Sw2TsATUP"},"outputs":[],"source":["!python train.py --imgsz 640 --batch 8 --epochs 100 --data /content/datasets/sl--yolov5-6/data.yaml --weights yolov5x.pt --name yolov5x_results --cache"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atWJww48BRis"},"outputs":[],"source":["# Start tensorboard\n","# Launch after you have started training\n","# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyiYAHvoBoc3"},"outputs":[],"source":["# we can also output some older school graphs if the tensor board isn't working for whatever reason...\n","from utils.plots import plot_results  # plot results.txt as results.png\n","Image(filename='/content/yolov5/runs/train/yolov5x_results/results.png', width=1000)  # view results.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZCyAL-EBprG"},"outputs":[],"source":["# first, display our ground truth data\n","print(\"GROUND TRUTH TRAINING DATA:\")\n","Image(filename='/content/yolov5/runs/train/yolov5x_results/test_batch0_labels.jpg', width=900)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L7qPSneSEaMj"},"outputs":[],"source":["# print out an augmented training example\n","print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n","Image(filename='/content/yolov5/runs/train/yolov5x_results/train_batch0.jpg', width=900)"]},{"cell_type":"markdown","metadata":{"id":"ffhiAT9KTqc_"},"source":["# Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crE1C4d7EbK1"},"outputs":[],"source":["!python val.py --weights /path/to/file/best.pt --data /path/to/file/dataset/data.yaml --img 640 --verbose --batch 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NgnxC221VvjD"},"outputs":[],"source":["# Plot Precision Recall curve\n","plt.plot(figsize=(20,20))\n","plt.title('Precision Recall curve', fontsize=20)\n","plt.tick_params(left = False, right = False , labelleft = False, labelbottom = False, bottom = False)\n","plt.imshow(mpimg.imread('runs_penguins/validation_on_test_data/PR_curve.png'))"]},{"cell_type":"markdown","metadata":{"id":"hCNZ9miFTn0_"},"source":["# Fine Tunning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yoshCz-OTqY7"},"outputs":[],"source":["!python train.py --imgsz 640 --hyp /path/to/file/hypfinetunning.yaml --batch 8 --epochs 100 --data /path/to/file/dataset/data.yaml --weights /path/to/file/hasiltraining/best.pt --name fine-tunning --cache"]},{"cell_type":"code","source":["!python val.py --weights /path/to/file/best.pt --data /path/to/file/dataset/data.yaml --img 640 --verbose --batch 8"],"metadata":{"id":"EchaOFdTV_Dy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VI5v9ujUnen"},"source":["# Detect"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8MgQimnGp4M"},"outputs":[],"source":["!python detect.py --weights /path/to/file/best.pt --img 640 --conf 0.4 --source /path/to/folder/test/images #--save-txt --save-conf --visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgAhnO39UmeD"},"outputs":[],"source":["#display inference on ALL test images\n","\n","import glob\n","from IPython.display import Image, display\n","\n","for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n","    display(Image(filename=imageName))\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7F9c1xpJVFa-"},"outputs":[],"source":["#Run inference on your model on a persistant, auto-scaling, cloud API\n","\n","#load model\n","model = project.version(dataset.version).model\n","\n","#choose random test set image\n","import os, random\n","test_set_loc = dataset.location + \"/test/images/\"\n","random_test_image = random.choice(os.listdir(test_set_loc))\n","print(\"running inference on \" + random_test_image)\n","\n","pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\n","pred"]},{"cell_type":"markdown","metadata":{"id":"hjwjE0G0Utfu"},"source":["# Export folder or just best.pt file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MfZrtupvUx7v"},"outputs":[],"source":["import zipfile\n","folder_path = '/path/to/file'\n","zip_file_path = '/path/to/file.zip'\n","\n","with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n","    # Iterate through all files and subdirectories in the folder\n","    for root, _, files in os.walk(folder_path):\n","        # Add each file to the zip file\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            zipf.write(file_path, os.path.relpath(file_path, folder_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0E4unLQVW0e"},"outputs":[],"source":["#export your model's weights for future use\n","from google.colab import files\n","files.download('./runs/train/exp/weights/best.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["SBq-z4d8_2u-"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}